{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorboard as tb\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.utils.tensorboard import SummaryWriter \n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import torchreid\n",
    "\n",
    "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BackboneFeatureExtractor(nn.Module):\n",
    "    def __init__(self, backbone):\n",
    "        super(BackboneFeatureExtractor, self).__init__()\n",
    "        self.backbone = backbone        \n",
    "        self.backbone.fc = nn.Identity()\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.backbone(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])\n",
    "\n",
    "preprocess_image = transforms.Compose([\n",
    "    transforms.Resize((256, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    normalize,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backbone = torchvision.models.vgg19(pretrained=True)\n",
    "# model = BackboneFeatureExtractor(backbone).cuda(1)\n",
    "# _ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torchreid.models.build_model(\n",
    "    name='resnet50',\n",
    "    num_classes=4101,\n",
    "    loss='softmax',\n",
    "    pretrained=True\n",
    ")\n",
    "\n",
    "model = model.cuda(1)\n",
    "checkpoint = torch.load('../resnet50_msmt17.pth')\n",
    "model.load_state_dict(checkpoint)\n",
    "_ = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate all embedings for images\n",
    "images_path = Path('/media/svakhreev/fast/generated_images/crops/body/')\n",
    "\n",
    "for image_filename in tqdm(images_path.iterdir()):\n",
    "    if image_filename.suffix.lower() not in ('.png', '.jpg'):\n",
    "        continue\n",
    "    image = Image.open(str(image_filename))\n",
    "    input_data = preprocess_image(image)[None,].cuda(1)\n",
    "    with torch.no_grad():\n",
    "        features = model(input_data).cpu().numpy()\n",
    "    np.save(str(images_path / f'{image_filename.stem}.npy'), features) # сохраняем эмбеддинги .npy в указанный путь\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
