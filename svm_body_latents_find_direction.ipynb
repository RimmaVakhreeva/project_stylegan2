{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import PIL\n",
    "import tqdm\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "\n",
    "import dnnlib\n",
    "import dnnlib.tflib as tflib\n",
    "import pretrained_networks\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import euclidean, cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерируем картинку и латентный вектор\n",
    "network_pkl = 'latest.pkl'\n",
    "print('Loading networks from \"%s\"...' % network_pkl)\n",
    "_G, _D, Gs = pretrained_networks.load_networks(network_pkl)\n",
    "\n",
    "\n",
    "def generate_img(Gs, W):\n",
    "    X = Gs.components.synthesis.run(W, randomize_noise=False, minibatch_size=1, print_progress=False,\n",
    "                                    output_transform=dict(func=tflib.convert_images_to_uint8, nchw_to_nhwc=True))\n",
    "    return PIL.Image.fromarray(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolate(latent_code,\n",
    "                       boundary,\n",
    "                       start_distance=-3.0,\n",
    "                       end_distance=3.0,\n",
    "                       steps=10):\n",
    "    \"\"\"Manipulates the given latent code with respect to a particular boundary.\n",
    "        Basically, this function takes a latent code and a boundary as inputs, and\n",
    "      outputs a collection of manipulated latent codes.\n",
    "      NOTE: Distance is sign sensitive.\n",
    "      Args:\n",
    "        latent_code: The input latent code for manipulation.\n",
    "        boundary: The semantic boundary as reference.\n",
    "        start_distance: The distance to the boundary where the manipulation starts.\n",
    "          (default: -3.0)\n",
    "        end_distance: The distance to the boundary where the manipulation ends.\n",
    "          (default: 3.0)\n",
    "        steps: Number of steps to move the latent code from start position to end\n",
    "      position. (default: 10)\n",
    "      \"\"\"\n",
    "    assert (latent_code.shape[0] == 1 and boundary.shape[0] == 1 and\n",
    "          len(boundary.shape) == 2 and\n",
    "          boundary.shape[1] == latent_code.shape[-1])\n",
    "\n",
    "    linspace = np.linspace(start_distance, end_distance, steps)\n",
    "    if len(latent_code.shape) == 2:\n",
    "        linspace = linspace - latent_code.dot(boundary.T) # linspace - латентный код z * вектор нормали n^T\n",
    "        linspace = linspace.reshape(-1, 1).astype(np.float32)\n",
    "        return latent_code + linspace * boundary # эта формула из статьи, где single attribute manipulation\n",
    "                                                                    # z_edit = z + alpha * n\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latents_base_path = Path('/media/svakhreev/fast/generated_images/latents/')\n",
    "base_path = Path('/media/svakhreev/fast/generated_images/crops/body')\n",
    "all_filenames = [path for path in base_path.iterdir() if path.suffix == '.npy']\n",
    "\n",
    "image_base_path = base_path / f'030131_1' # опорная картинка\n",
    "image = cv2.imread(f'{image_base_path}.png')\n",
    "feat_1 = np.load(f'{image_base_path}.npy')[0] # латетный вектор опорной картинки\n",
    "\n",
    "PIL.Image.open(f'{image_base_path}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# списки признаков латентного пространства\n",
    "\n",
    "dist_thresh = 22. # пороговое расстояние\n",
    "distances = []\n",
    "for filename in tqdm.tqdm(all_filenames):\n",
    "    if filename.suffix != '.npy':\n",
    "        continue\n",
    "    feat_2 = np.load(str(filename))[0]\n",
    "    distances.append(euclidean(feat_1, feat_2))\n",
    "    \n",
    "sorted_dist_idxes = np.argsort(distances)\n",
    "top_k_nearest = (np.array(distances) <= dist_thresh).sum()\n",
    "min_idxes = sorted_dist_idxes[:top_k_nearest] \n",
    "max_idxes = sorted_dist_idxes[-5000:]\n",
    "\n",
    "min_features = [np.load(str(latents_base_path / all_filenames[idx].name))[0]\n",
    "                for idx in min_idxes]\n",
    "max_features = [np.load(str(latents_base_path / all_filenames[idx].name))[0]\n",
    "                for idx in max_idxes]\n",
    "print(top_k_nearest)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(min_features + max_features)\n",
    "y = pd.DataFrame([[0 if idx < len(min_features) else 1] for idx in range(len(X))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC(kernel='linear', class_weight='balanced')\n",
    "svc.fit(X, y) \n",
    "print(svc.score(X, y))\n",
    "\n",
    "boundary = svc.coef_.reshape(1, 512).astype(np.float32) # разделяющая граница\n",
    "boundary /= np.linalg.norm(boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# генерация произвольной картинки с помощью обученного stylegan2\n",
    "\n",
    "truncation = 0.7\n",
    "Z = np.random.randn(1, Gs.input_shape[1])\n",
    "W = Gs.components.mapping.run(Z, None, minibatch_size=1)\n",
    "\n",
    "dlatent_avg = Gs.get_var('dlatent_avg')\n",
    "W = (W[np.newaxis] - dlatent_avg) * np.reshape([truncation, -truncation], [-1, 1, 1, 1]) + dlatent_avg\n",
    "W = np.append(W[0], W[1], axis=0)\n",
    "W = W[:, :512]\n",
    "W = W.reshape((2, 16, 512))[[0]]\n",
    "\n",
    "generate_img(Gs, W) # эту картинку будем изменять"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_latents = linear_interpolate(latent_code=W, boundary=boundary, \n",
    "                                 start_distance=0, end_distance=-30,\n",
    "                                 steps=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = cv2.VideoWriter('./out.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 25,\n",
    "                          (512, 1024))\n",
    "for feat in tqdm.tqdm(new_latents):\n",
    "    image = generate_img(Gs, feat[None, ])\n",
    "    writer.write(np.array(image)[..., ::-1])\n",
    "writer.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
